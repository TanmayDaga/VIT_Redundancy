{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a25dee4-c75c-43c6-8b8b-56dd2100a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_OF_FOLDER:str = \"/home/shared/val2\"\n",
    "PATH_OF_CONFIG_FILE:str = \"/home/shared/imagenet_class_index.json\"\n",
    "MODEL_NAME:str = \"vit_base_patch16_224\"\n",
    "NO_OF_CLASSES = 10\n",
    "DEVICE_CUDA = \"cuda:1\"\n",
    "DEVICE_CPU = \"cpu\"\n",
    "MINIMUM_TOTAL_OCCURENCES = 80\n",
    "SCALE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa5053-ebf3-4c61-afd1-b5daecfb2b53",
   "metadata": {},
   "source": [
    "#### Some variables to be reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "146b2567-b6ee-4e98-b383-6a5f086027d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import resolve_data_config\n",
    "from torchvision.transforms import Compose\n",
    "from timm.data.transforms_factory import create_transform\n",
    "config:dict = resolve_data_config({}, model = MODEL_NAME)\n",
    "TRANSFORMATION_COMPOSE :Compose = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37bc8994-e740-4f12-9c8c-575c1020f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from cudf.core.dataframe import DataFrame\n",
    "import cupy\n",
    "import cudf\n",
    "\n",
    "class HelperFuntions:\n",
    "    \n",
    "    @staticmethod\n",
    "    def list_files_os_listdir(directory_path):\n",
    "        \"\"\"\n",
    "        Lists all files in a given directory using os.listdir().\n",
    "        Returns a list of full paths to the files.\n",
    "        \"\"\"\n",
    "        files = []\n",
    "        try:\n",
    "            # Get all entries (files and directories)\n",
    "            for item_name in os.listdir(directory_path):\n",
    "                # Construct the full path\n",
    "                item_path = os.path.join(directory_path, item_name)\n",
    "                # Check if it's a file\n",
    "                if os.path.isfile(item_path):\n",
    "                    files.append(item_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Directory '{directory_path}' not found.\")\n",
    "        except PermissionError:\n",
    "            print(f\"Error: Permission denied for directory '{directory_path}'.\")\n",
    "        return files\n",
    "\n",
    "    @staticmethod\n",
    "    def get_input_tensor(file_name:str) -> Tensor:\n",
    "        img = Image.open(file_name).convert(\"RGB\")\n",
    "        input_tensor = TRANSFORMATION_COMPOSE(img).to(device).unsqueeze(0)\n",
    "        return input_tensor\n",
    "\n",
    "    @staticmethod\n",
    "    def multiply_two_matrices(matrix_a:Tensor, matrix_b:Tensor) -> Tensor:\n",
    "        m, n = matrix_a.shape\n",
    "        n2 , p = matrix_b.shape\n",
    "        matrix_a = matrix_a.unsqueeze(2).expand(m, n, p)\n",
    "        matrix_b = matrix_b.t().unsqueeze(0).expand(m, p, n).transpose(1, 2)\n",
    "        result = matrix_a * matrix_b\n",
    "        matrix_a = matrix_a.reshape(-1)\n",
    "        matrix_b = matrix_b.reshape(-1)\n",
    "        result = result.reshape(-1)\n",
    "        ops = torch.stack([matrix_a, matrix_b, result], dim=1)\n",
    "        del matrix_a, matrix_b, result\n",
    "        return ops\n",
    "\n",
    "    @staticmethod\n",
    "    def find_common_operations(ops:Tensor) -> DataFrame:\n",
    "        dlpack = torch.utils.dlpack.to_dlpack(ops)\n",
    "        cupy_array = cupy.from_dlpack(dlpack)\n",
    "        del dlpack, ops\n",
    "        df = cudf.DataFrame({\n",
    "            \"a\": cupy_array[:, 0],\n",
    "            \"b\": cupy_array[:, 1],\n",
    "            \"r\": cupy_array[:, 2],\n",
    "        })\n",
    "        df_copy = df.copy()\n",
    "        del df, cupy_array\n",
    "        # Round columns\n",
    "        df_copy[\"rounded_r\"] = df_copy[\"r\"].round(SCALE)\n",
    "        df_copy[\"a_rounded\"] = df_copy[\"a\"].round(SCALE)\n",
    "        df_copy[\"b_rounded\"] = df_copy[\"b\"].round(SCALE)\n",
    "        df_copy[\"count\"] = cudf.Series(1, index=df_copy.index, dtype='uint32')\n",
    "        \n",
    "        # Compute operands\n",
    "        df_copy[\"operand1\"] = df_copy[[\"a_rounded\", \"b_rounded\"]].min(axis=1)\n",
    "        df_copy[\"operand2\"] = df_copy[[\"a_rounded\", \"b_rounded\"]].max(axis=1)\n",
    "\n",
    "        # Group, aggregate, and create a new DataFrame\n",
    "        new_df = (\n",
    "            df_copy.groupby([\"rounded_r\", \"operand1\", \"operand2\"])\n",
    "                   .agg({\"count\": \"sum\"})\n",
    "                   .rename(columns={\"count\": \"total_occurrences\"})\n",
    "                   .reset_index()\n",
    "        )\n",
    "        \n",
    "        del df_copy\n",
    "        \n",
    "        new_df = new_df[new_df[\"total_occurrences\"] >= MINIMUM_TOTAL_OCCURENCES]\n",
    "        \n",
    "        # Sort and limit\n",
    "        return new_df.sort_values(\n",
    "            by=[\"total_occurrences\", \"operand2\"],\n",
    "            ascending=[False, False]\n",
    "        )\n",
    "\n",
    "    def merge_two_dfs(df1:DataFrame, df2:DataFrame) -> DataFrame:\n",
    "        columns_to_match = ['rounded_r', 'operand1', 'operand2']\n",
    "        merged_gdf = df1.merge(df2, on=columns_to_match, how='outer', suffixes=('_df1', '_df2'))\n",
    "        merged_gdf['total_occurrences_summed'] = merged_gdf['total_occurrences_df1'].fillna(0) + merged_gdf['total_occurrences_df2'].fillna(0)\n",
    "        merged_gdf = merged_gdf.rename(columns={'total_occurrences_summed': 'total_occurrences'})\n",
    "        columns_to_drop = ['total_occurrences_df1', 'total_occurrences_df2']\n",
    "        merged_gdf = merged_gdf.drop(columns=columns_to_drop).sort_values(by = [\"total_occurrences\", \"operand2\"], ascending = [False, False])\n",
    "        torch.cuda.empty_cache()\n",
    "        return merged_gdf\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc7ce1-5670-4adc-91a6-f63784384612",
   "metadata": {},
   "source": [
    "### Getting Image paths with there classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42961a43-30f4-4417-984e-8b5dcef7992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random, os\n",
    "available_options:dict = {}\n",
    "with open(PATH_OF_CONFIG_FILE, 'r') as file:\n",
    "    available_options = json.load(file)\n",
    "# {882: ['n04517823', 'vacuum'], 910: ['n04597913', 'wooden_spoon'],}\n",
    "CLASS_LIST = {i: available_options[str(i)] for i in random.sample(range(0, 1000), NO_OF_CLASSES)}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "{'n02096294': ['/home/shared/val2/n02096294/ILSVRC2012_val_00009052.JPEG'],\n",
    " 'n02870880': ['/home/shared/val2/n02870880/ILSVRC2012_val_00009820.JPEG'],\n",
    "\"\"\"\n",
    "FILE_PATHS ={x[0]: HelperFuntions.list_files_os_listdir(os.path.join(PATH_OF_FOLDER, x[0])) for x in CLASS_LIST.values()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b54fde-5240-4de3-952c-bb275fc45480",
   "metadata": {},
   "source": [
    "## Setting up intial matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdacd0c7-3d2e-478a-9864-accc6925531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from timm import create_model\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "device = torch.device(DEVICE_CUDA if torch.cuda.is_available() else DEVICE_CPU)\n",
    "model = create_model(MODEL_NAME, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "matrix_a = model.patch_embed.proj.weight.view(768,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6940cc-0c81-4d10-9769-38f7014e6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def get_for_patch_embed(file_path:str) -> DataFrame:\n",
    "    matrix_b = F.unfold(HelperFuntions.get_input_tensor(file_path), kernel_size = (16,16), stride = (16,16))[0]\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    df = HelperFuntions.find_common_operations(HelperFuntions.multiply_two_matrices(matrix_a, matrix_b))\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    return df\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c41480e5-d995-44f3-88cd-27ef2234e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_for_class(index) -> DataFrame:\n",
    "    class_selected = FILE_PATHS[list(FILE_PATHS.keys())[index]]\n",
    "    \n",
    "    accum :DataFrame = get_for_patch_embed(class_selected[0])\n",
    "    for i in range(1, len(class_selected)):\n",
    "        df = get_for_patch_embed(class_selected[i])\n",
    "        accum = HelperFuntions.merge_two_dfs(df, accum)\n",
    "        del df\n",
    "    torch.cuda.empty_cache()\n",
    "    return accum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5517f24a-b6d3-43ed-9aef-02d29f35d101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rounded_r</th>\n",
       "      <th>operand1</th>\n",
       "      <th>operand2</th>\n",
       "      <th>total_occurrences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17664</th>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>2.24891</td>\n",
       "      <td>25380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17665</th>\n",
       "      <td>-0.00058</td>\n",
       "      <td>-0.00026</td>\n",
       "      <td>2.24891</td>\n",
       "      <td>24331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17666</th>\n",
       "      <td>0.00263</td>\n",
       "      <td>0.00117</td>\n",
       "      <td>2.24891</td>\n",
       "      <td>24262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17667</th>\n",
       "      <td>0.00236</td>\n",
       "      <td>0.00105</td>\n",
       "      <td>2.24891</td>\n",
       "      <td>23447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17668</th>\n",
       "      <td>-0.00184</td>\n",
       "      <td>-0.00082</td>\n",
       "      <td>2.24891</td>\n",
       "      <td>23046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536576</th>\n",
       "      <td>0.05298</td>\n",
       "      <td>-1.47329</td>\n",
       "      <td>-0.03596</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536577</th>\n",
       "      <td>0.07405</td>\n",
       "      <td>-2.01821</td>\n",
       "      <td>-0.03669</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536580</th>\n",
       "      <td>0.05874</td>\n",
       "      <td>-1.59529</td>\n",
       "      <td>-0.03682</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536578</th>\n",
       "      <td>0.08657</td>\n",
       "      <td>-2.01821</td>\n",
       "      <td>-0.04289</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536579</th>\n",
       "      <td>0.08679</td>\n",
       "      <td>-2.01821</td>\n",
       "      <td>-0.04300</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2541848 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rounded_r  operand1  operand2  total_occurrences\n",
       "17664      0.00020   0.00009   2.24891              25380\n",
       "17665     -0.00058  -0.00026   2.24891              24331\n",
       "17666      0.00263   0.00117   2.24891              24262\n",
       "17667      0.00236   0.00105   2.24891              23447\n",
       "17668     -0.00184  -0.00082   2.24891              23046\n",
       "...            ...       ...       ...                ...\n",
       "2536576    0.05298  -1.47329  -0.03596                 80\n",
       "2536577    0.07405  -2.01821  -0.03669                 80\n",
       "2536580    0.05874  -1.59529  -0.03682                 80\n",
       "2536578    0.08657  -2.01821  -0.04289                 80\n",
       "2536579    0.08679  -2.01821  -0.04300                 80\n",
       "\n",
       "[2541848 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum = get_for_class(0)\n",
    "for i in range(1, len(FILE_PATHS.keys())):\n",
    "    df = get_for_class(i)\n",
    "    accum = HelperFuntions.merge_two_dfs(accum, df)\n",
    "    del df\n",
    "torch.cuda.empty_cache()\n",
    "accum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a42ac856-3ad6-4af9-a18f-db78cef6be2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24856749-1d95-4f7d-91a4-1bad087bab0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
